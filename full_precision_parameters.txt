Layer: embedding.weight
Shape: [128, 28]
Values:
[[ 0.08285744  0.09530894 -0.00737797 ... -0.11923575 -0.13120359
   0.10864304]
 [ 0.06452103  0.0581961  -0.08033407 ... -0.14996904  0.0286731
   0.09684746]
 [ 0.05895546  0.00282732  0.04876578 ...  0.07846217  0.0548223
   0.1620682 ]
 ...
 [ 0.13464604  0.02477694 -0.02652606 ... -0.06722355  0.16209696
   0.15198506]
 [ 0.11930467  0.04225582 -0.17327248 ... -0.04706278  0.17291076
   0.03529535]
 [-0.06295158  0.10916312 -0.13406576 ...  0.14530633  0.0914381
   0.10459055]]
============================================================
Layer: embedding.bias
Shape: [128]
Values:
[-0.03257567  0.11100067 -0.09372023 -0.04644729 -0.03224918 -0.16819353
  0.18253438  0.05230896 -0.1389858   0.00237936 -0.1347061   0.14982025
 -0.11146025 -0.15180531  0.15795074 -0.16450033  0.11847676 -0.10948217
 -0.11029194  0.10263892  0.04106984 -0.08508011  0.13974328 -0.06703458
 -0.0605469   0.1278096  -0.1705911  -0.04914553 -0.13181219  0.15422724
  0.12166576 -0.08434192  0.08581688 -0.12062212 -0.16593292 -0.01591136
 -0.04019916 -0.10303111 -0.022607   -0.14655733 -0.17221758 -0.08648169
 -0.1114902  -0.16841775 -0.08626337  0.10965715 -0.03487903  0.03381322
  0.08888091 -0.10881125  0.07012905 -0.0299045  -0.02662753  0.09022038
  0.14707007  0.03350456  0.09619428  0.06222324  0.09656937 -0.08136127
 -0.183697    0.17781644  0.14784099  0.02772884  0.18630497 -0.0279225
 -0.18565938 -0.10946106  0.06682856  0.16272913  0.11292492 -0.1337355
  0.14752303  0.08625217 -0.17660184  0.17180337 -0.10058247 -0.07668836
  0.08405568  0.11371155  0.16677524  0.07538567 -0.09712825  0.12353833
  0.18357803 -0.07685935  0.0834275   0.15465091  0.07100601  0.01456511
 -0.12311399 -0.01583023 -0.1687728   0.17984404 -0.0471866  -0.06648149
 -0.08276603  0.0855919  -0.05602372  0.15508889 -0.18049824 -0.15707499
  0.1426747   0.1269757   0.15296884 -0.14948829  0.07216121  0.13547473
 -0.06335106 -0.06860711  0.06989752  0.08440231  0.12234716  0.12049319
  0.0663489   0.14653619  0.16077168 -0.12801808 -0.09446931  0.16801532
  0.00688154  0.03891085  0.10872371 -0.18485856 -0.03241497  0.06450187
 -0.12560692  0.0607615 ]
============================================================
Layer: transformer.layers.0.self_attn.in_proj_weight
Shape: [384, 128]
Values:
[[ 0.08496369  0.0408392   0.06628848 ... -0.07991664  0.09417263
  -0.04314322]
 [ 0.00303534 -0.1076762   0.05317575 ... -0.06270213 -0.01683621
   0.01632677]
 [-0.02386014  0.10525445  0.01205523 ...  0.07857742  0.0271217
  -0.05860695]
 ...
 [-0.07376282 -0.07301705  0.10066066 ... -0.00426849 -0.0449537
  -0.01823892]
 [-0.0489037   0.00239008  0.01896689 ... -0.10270438  0.05206899
  -0.05720704]
 [-0.00650587 -0.08715158  0.07748011 ... -0.08025157  0.00618912
   0.09045681]]
============================================================
Layer: transformer.layers.0.self_attn.in_proj_bias
Shape: [384]
Values:
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
============================================================
Layer: transformer.layers.0.self_attn.out_proj.weight
Shape: [128, 128]
Values:
[[-0.05976808  0.08534684  0.04954193 ... -0.05977006 -0.01228316
  -0.04066557]
 [-0.01776867 -0.0366843  -0.0693861  ... -0.06482913 -0.01998977
  -0.02498869]
 [-0.00187001 -0.08102067  0.02472389 ...  0.08711173 -0.03916664
   0.01720282]
 ...
 [ 0.02576252  0.08270115  0.04331253 ... -0.01169178 -0.07503812
  -0.05286781]
 [ 0.05649849  0.06926287  0.03295065 ... -0.01100015  0.04596414
   0.01396297]
 [ 0.06421054 -0.04042811  0.06311508 ... -0.01908105 -0.03458769
  -0.00785995]]
============================================================
Layer: transformer.layers.0.self_attn.out_proj.bias
Shape: [128]
Values:
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0.]
============================================================
Layer: transformer.layers.0.linear1.weight
Shape: [256, 128]
Values:
[[-0.02668259  0.06627373 -0.04753653 ... -0.00493823 -0.07501518
  -0.07706226]
 [-0.00263538 -0.06299982  0.055367   ... -0.06368174  0.03359608
   0.00011393]
 [ 0.07941584  0.01584958  0.05232064 ... -0.00248961 -0.0244178
  -0.04740095]
 ...
 [ 0.00623216  0.03155998 -0.02135975 ...  0.03531036 -0.01292417
  -0.02816444]
 [-0.0672042  -0.07248329 -0.00948066 ...  0.02434518  0.05853511
   0.06756983]
 [-0.01840482  0.00017585 -0.03132377 ... -0.08045256  0.07615644
  -0.03822488]]
============================================================
Layer: transformer.layers.0.linear1.bias
Shape: [256]
Values:
[-0.08652976 -0.0131571  -0.0135335   0.06151716  0.07407045  0.06008928
 -0.01840304  0.05970719 -0.02761069 -0.06348984 -0.08388931  0.08217492
  0.07410213 -0.06356643 -0.07355483  0.00863848  0.05555945  0.05289418
 -0.03851765 -0.01794668  0.0308907   0.00589144  0.01711454 -0.04175722
 -0.06196022  0.08144365  0.02061015 -0.06859149  0.07070573  0.06327163
  0.08593155  0.0611845  -0.07620461  0.07591907 -0.02478638  0.04824976
 -0.03302426  0.07969106  0.07547086  0.08721491  0.02655745  0.00592692
  0.07862879  0.02708177  0.07883241  0.05565221  0.06546015  0.00049708
 -0.04337706  0.08223649  0.0756916   0.02600382 -0.04647439  0.07758594
 -0.08440091 -0.03689942 -0.03627955 -0.04179931 -0.0020998   0.08360758
  0.07488944 -0.01235665 -0.08369267 -0.06663945  0.06773032 -0.07998966
  0.0275399   0.01189701  0.01420057  0.01748193 -0.00199731  0.01957617
 -0.06006122  0.02920876 -0.02892284 -0.04980435  0.02281997  0.04281052
  0.02824308  0.01971674  0.02428716  0.05872367 -0.00632857  0.04451411
 -0.05758934 -0.08234907 -0.02862946 -0.05625254  0.04544128  0.07766891
 -0.03695638 -0.0271703   0.08751119 -0.08062497  0.05940279  0.04824153
 -0.05789584  0.06574195  0.04818597 -0.04095209 -0.04030837 -0.08742955
  0.05326655 -0.05280702  0.00268041  0.05237787 -0.02624873  0.05223864
 -0.06303857  0.07902545  0.00179429  0.06504265  0.05422344 -0.06100515
 -0.02868044 -0.03362433  0.07876233  0.04492814 -0.05142725 -0.04056769
 -0.0493095   0.071517   -0.07169299  0.01260646 -0.03795232 -0.05841252
  0.07834999  0.07692096 -0.01772807  0.06922726 -0.02033679 -0.07838511
  0.07261505 -0.04737359 -0.00085694 -0.06806602 -0.0092821  -0.01365148
 -0.02118846  0.04188993  0.08470925  0.04053403 -0.07093997  0.07247785
 -0.01977881  0.00305901  0.04018996  0.01709229  0.03476205  0.0443315
  0.04045136  0.06351269  0.03617466 -0.08211654 -0.00154012  0.0683698
 -0.03263449 -0.07284841 -0.05744208  0.02136196 -0.08070225  0.00088994
 -0.01262437  0.02263232  0.00617408  0.01653058  0.00117894  0.00151455
 -0.01900245  0.05553583  0.0658078   0.02813823 -0.00082447  0.03427138
 -0.06790249 -0.00942539  0.06365883 -0.0614199  -0.01692782 -0.04492566
  0.00832902 -0.03870309 -0.02932263 -0.08303803  0.08487005  0.00282933
  0.03004364 -0.05967429  0.02158137 -0.03256439  0.01105845  0.0115564
 -0.00307292 -0.05723631 -0.08099007 -0.00310784 -0.07493307  0.08117042
  0.06194521  0.06333233 -0.0091701   0.0406974  -0.03437199 -0.04524061
 -0.01121927 -0.04731621 -0.07823142  0.01988982 -0.01530347  0.0397807
  0.02429383 -0.03419415  0.06698234  0.0303529   0.04917363  0.0330906
 -0.08754587  0.06107498 -0.07930672 -0.03573161  0.02145929 -0.0055164
  0.06431627  0.08251195 -0.03493208  0.03588854  0.03760438  0.06925676
 -0.07427397  0.03750739  0.04392845 -0.04094883 -0.07719219  0.07696753
  0.07751351  0.05241812 -0.05084726  0.0223726  -0.03176586  0.00468952
 -0.07796053  0.0499401   0.0115399   0.08702057  0.00732127 -0.01309412
 -0.04436375 -0.01011222 -0.06553689 -0.08680069 -0.07073461 -0.03928982
  0.04520371  0.0469565   0.02880929 -0.01833989]
============================================================
Layer: transformer.layers.0.linear2.weight
Shape: [128, 256]
Values:
[[ 0.0452059  -0.02313939  0.03736281 ... -0.05963016  0.05659345
   0.03715707]
 [-0.01654788  0.04163754  0.01530872 ... -0.04241093 -0.0124036
  -0.01882766]
 [-0.05148666 -0.04839454  0.05384638 ... -0.00740131 -0.00873149
   0.00706192]
 ...
 [ 0.03842217 -0.02255641 -0.01834152 ... -0.00649662  0.02586147
   0.06167987]
 [-0.00064773 -0.01099353  0.03949562 ...  0.0262919   0.00807852
  -0.05038115]
 [ 0.01262912 -0.00725354 -0.03269034 ...  0.02273608 -0.04783542
   0.02654231]]
============================================================
Layer: transformer.layers.0.linear2.bias
Shape: [128]
Values:
[-0.03170136 -0.00578491 -0.02246751  0.01142528  0.05625474 -0.01958849
 -0.00125018 -0.0065854   0.0368437   0.00141668 -0.06136401 -0.01107386
 -0.02688377 -0.03708035 -0.03675938  0.00874493  0.01609477 -0.03607848
 -0.03192201  0.00446435  0.04767908 -0.01333421 -0.0203365   0.04853527
 -0.02540435  0.01145788 -0.01331595 -0.00864787  0.02731661  0.03156182
 -0.03018989  0.06014901  0.05973764 -0.00986585  0.01977737  0.04012921
  0.01461615  0.02738708 -0.03918497 -0.06123136  0.06084789  0.00752373
  0.02856326 -0.0574182   0.04192862  0.04916362  0.03797967 -0.02635596
 -0.00886998 -0.03309377  0.0502475  -0.02381929 -0.02925419 -0.01748184
  0.03232282  0.03224241 -0.03772201 -0.03458553  0.04908418  0.02439177
 -0.00795154  0.01062711  0.03915027  0.04733525 -0.0610709  -0.03551394
 -0.05616087  0.02149332  0.0465675   0.06144816 -0.03555659 -0.03062538
  0.01698751 -0.0080481  -0.00080757 -0.04706598 -0.04981921  0.00058621
  0.00266064 -0.05234421  0.04812597  0.03665516 -0.05560306 -0.0400686
  0.02059481  0.00907721 -0.04627042 -0.03444877  0.01198883  0.02787988
 -0.02779789  0.03441419 -0.05627414 -0.00390814  0.00270382 -0.04244551
  0.0019217  -0.0243857  -0.01564684  0.00379801  0.00334993  0.04215672
  0.04963542 -0.04658589 -0.02116164 -0.0242295   0.06174654 -0.00194859
 -0.01782588  0.00342433 -0.04238862 -0.03002322  0.01558743  0.03647093
 -0.02765558  0.02795156 -0.03027602 -0.02159561 -0.03677442 -0.00326332
  0.00504552  0.04535466 -0.03077953  0.02900297 -0.00912066  0.05053662
 -0.0170843   0.0350126 ]
============================================================
Layer: transformer.layers.0.norm1.weight
Shape: [128]
Values:
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1.]
============================================================
Layer: transformer.layers.0.norm1.bias
Shape: [128]
Values:
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0.]
============================================================
Layer: transformer.layers.0.norm2.weight
Shape: [128]
Values:
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1.]
============================================================
Layer: transformer.layers.0.norm2.bias
Shape: [128]
Values:
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0.]
============================================================
Layer: transformer.layers.1.self_attn.in_proj_weight
Shape: [384, 128]
Values:
[[ 0.08496369  0.0408392   0.06628848 ... -0.07991664  0.09417263
  -0.04314322]
 [ 0.00303534 -0.1076762   0.05317575 ... -0.06270213 -0.01683621
   0.01632677]
 [-0.02386014  0.10525445  0.01205523 ...  0.07857742  0.0271217
  -0.05860695]
 ...
 [-0.07376282 -0.07301705  0.10066066 ... -0.00426849 -0.0449537
  -0.01823892]
 [-0.0489037   0.00239008  0.01896689 ... -0.10270438  0.05206899
  -0.05720704]
 [-0.00650587 -0.08715158  0.07748011 ... -0.08025157  0.00618912
   0.09045681]]
============================================================
Layer: transformer.layers.1.self_attn.in_proj_bias
Shape: [384]
Values:
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]
============================================================
Layer: transformer.layers.1.self_attn.out_proj.weight
Shape: [128, 128]
Values:
[[-0.05976808  0.08534684  0.04954193 ... -0.05977006 -0.01228316
  -0.04066557]
 [-0.01776867 -0.0366843  -0.0693861  ... -0.06482913 -0.01998977
  -0.02498869]
 [-0.00187001 -0.08102067  0.02472389 ...  0.08711173 -0.03916664
   0.01720282]
 ...
 [ 0.02576252  0.08270115  0.04331253 ... -0.01169178 -0.07503812
  -0.05286781]
 [ 0.05649849  0.06926287  0.03295065 ... -0.01100015  0.04596414
   0.01396297]
 [ 0.06421054 -0.04042811  0.06311508 ... -0.01908105 -0.03458769
  -0.00785995]]
============================================================
Layer: transformer.layers.1.self_attn.out_proj.bias
Shape: [128]
Values:
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0.]
============================================================
Layer: transformer.layers.1.linear1.weight
Shape: [256, 128]
Values:
[[-0.02668259  0.06627373 -0.04753653 ... -0.00493823 -0.07501518
  -0.07706226]
 [-0.00263538 -0.06299982  0.055367   ... -0.06368174  0.03359608
   0.00011393]
 [ 0.07941584  0.01584958  0.05232064 ... -0.00248961 -0.0244178
  -0.04740095]
 ...
 [ 0.00623216  0.03155998 -0.02135975 ...  0.03531036 -0.01292417
  -0.02816444]
 [-0.0672042  -0.07248329 -0.00948066 ...  0.02434518  0.05853511
   0.06756983]
 [-0.01840482  0.00017585 -0.03132377 ... -0.08045256  0.07615644
  -0.03822488]]
============================================================
Layer: transformer.layers.1.linear1.bias
Shape: [256]
Values:
[-0.08652976 -0.0131571  -0.0135335   0.06151716  0.07407045  0.06008928
 -0.01840304  0.05970719 -0.02761069 -0.06348984 -0.08388931  0.08217492
  0.07410213 -0.06356643 -0.07355483  0.00863848  0.05555945  0.05289418
 -0.03851765 -0.01794668  0.0308907   0.00589144  0.01711454 -0.04175722
 -0.06196022  0.08144365  0.02061015 -0.06859149  0.07070573  0.06327163
  0.08593155  0.0611845  -0.07620461  0.07591907 -0.02478638  0.04824976
 -0.03302426  0.07969106  0.07547086  0.08721491  0.02655745  0.00592692
  0.07862879  0.02708177  0.07883241  0.05565221  0.06546015  0.00049708
 -0.04337706  0.08223649  0.0756916   0.02600382 -0.04647439  0.07758594
 -0.08440091 -0.03689942 -0.03627955 -0.04179931 -0.0020998   0.08360758
  0.07488944 -0.01235665 -0.08369267 -0.06663945  0.06773032 -0.07998966
  0.0275399   0.01189701  0.01420057  0.01748193 -0.00199731  0.01957617
 -0.06006122  0.02920876 -0.02892284 -0.04980435  0.02281997  0.04281052
  0.02824308  0.01971674  0.02428716  0.05872367 -0.00632857  0.04451411
 -0.05758934 -0.08234907 -0.02862946 -0.05625254  0.04544128  0.07766891
 -0.03695638 -0.0271703   0.08751119 -0.08062497  0.05940279  0.04824153
 -0.05789584  0.06574195  0.04818597 -0.04095209 -0.04030837 -0.08742955
  0.05326655 -0.05280702  0.00268041  0.05237787 -0.02624873  0.05223864
 -0.06303857  0.07902545  0.00179429  0.06504265  0.05422344 -0.06100515
 -0.02868044 -0.03362433  0.07876233  0.04492814 -0.05142725 -0.04056769
 -0.0493095   0.071517   -0.07169299  0.01260646 -0.03795232 -0.05841252
  0.07834999  0.07692096 -0.01772807  0.06922726 -0.02033679 -0.07838511
  0.07261505 -0.04737359 -0.00085694 -0.06806602 -0.0092821  -0.01365148
 -0.02118846  0.04188993  0.08470925  0.04053403 -0.07093997  0.07247785
 -0.01977881  0.00305901  0.04018996  0.01709229  0.03476205  0.0443315
  0.04045136  0.06351269  0.03617466 -0.08211654 -0.00154012  0.0683698
 -0.03263449 -0.07284841 -0.05744208  0.02136196 -0.08070225  0.00088994
 -0.01262437  0.02263232  0.00617408  0.01653058  0.00117894  0.00151455
 -0.01900245  0.05553583  0.0658078   0.02813823 -0.00082447  0.03427138
 -0.06790249 -0.00942539  0.06365883 -0.0614199  -0.01692782 -0.04492566
  0.00832902 -0.03870309 -0.02932263 -0.08303803  0.08487005  0.00282933
  0.03004364 -0.05967429  0.02158137 -0.03256439  0.01105845  0.0115564
 -0.00307292 -0.05723631 -0.08099007 -0.00310784 -0.07493307  0.08117042
  0.06194521  0.06333233 -0.0091701   0.0406974  -0.03437199 -0.04524061
 -0.01121927 -0.04731621 -0.07823142  0.01988982 -0.01530347  0.0397807
  0.02429383 -0.03419415  0.06698234  0.0303529   0.04917363  0.0330906
 -0.08754587  0.06107498 -0.07930672 -0.03573161  0.02145929 -0.0055164
  0.06431627  0.08251195 -0.03493208  0.03588854  0.03760438  0.06925676
 -0.07427397  0.03750739  0.04392845 -0.04094883 -0.07719219  0.07696753
  0.07751351  0.05241812 -0.05084726  0.0223726  -0.03176586  0.00468952
 -0.07796053  0.0499401   0.0115399   0.08702057  0.00732127 -0.01309412
 -0.04436375 -0.01011222 -0.06553689 -0.08680069 -0.07073461 -0.03928982
  0.04520371  0.0469565   0.02880929 -0.01833989]
============================================================
Layer: transformer.layers.1.linear2.weight
Shape: [128, 256]
Values:
[[ 0.0452059  -0.02313939  0.03736281 ... -0.05963016  0.05659345
   0.03715707]
 [-0.01654788  0.04163754  0.01530872 ... -0.04241093 -0.0124036
  -0.01882766]
 [-0.05148666 -0.04839454  0.05384638 ... -0.00740131 -0.00873149
   0.00706192]
 ...
 [ 0.03842217 -0.02255641 -0.01834152 ... -0.00649662  0.02586147
   0.06167987]
 [-0.00064773 -0.01099353  0.03949562 ...  0.0262919   0.00807852
  -0.05038115]
 [ 0.01262912 -0.00725354 -0.03269034 ...  0.02273608 -0.04783542
   0.02654231]]
============================================================
Layer: transformer.layers.1.linear2.bias
Shape: [128]
Values:
[-0.03170136 -0.00578491 -0.02246751  0.01142528  0.05625474 -0.01958849
 -0.00125018 -0.0065854   0.0368437   0.00141668 -0.06136401 -0.01107386
 -0.02688377 -0.03708035 -0.03675938  0.00874493  0.01609477 -0.03607848
 -0.03192201  0.00446435  0.04767908 -0.01333421 -0.0203365   0.04853527
 -0.02540435  0.01145788 -0.01331595 -0.00864787  0.02731661  0.03156182
 -0.03018989  0.06014901  0.05973764 -0.00986585  0.01977737  0.04012921
  0.01461615  0.02738708 -0.03918497 -0.06123136  0.06084789  0.00752373
  0.02856326 -0.0574182   0.04192862  0.04916362  0.03797967 -0.02635596
 -0.00886998 -0.03309377  0.0502475  -0.02381929 -0.02925419 -0.01748184
  0.03232282  0.03224241 -0.03772201 -0.03458553  0.04908418  0.02439177
 -0.00795154  0.01062711  0.03915027  0.04733525 -0.0610709  -0.03551394
 -0.05616087  0.02149332  0.0465675   0.06144816 -0.03555659 -0.03062538
  0.01698751 -0.0080481  -0.00080757 -0.04706598 -0.04981921  0.00058621
  0.00266064 -0.05234421  0.04812597  0.03665516 -0.05560306 -0.0400686
  0.02059481  0.00907721 -0.04627042 -0.03444877  0.01198883  0.02787988
 -0.02779789  0.03441419 -0.05627414 -0.00390814  0.00270382 -0.04244551
  0.0019217  -0.0243857  -0.01564684  0.00379801  0.00334993  0.04215672
  0.04963542 -0.04658589 -0.02116164 -0.0242295   0.06174654 -0.00194859
 -0.01782588  0.00342433 -0.04238862 -0.03002322  0.01558743  0.03647093
 -0.02765558  0.02795156 -0.03027602 -0.02159561 -0.03677442 -0.00326332
  0.00504552  0.04535466 -0.03077953  0.02900297 -0.00912066  0.05053662
 -0.0170843   0.0350126 ]
============================================================
Layer: transformer.layers.1.norm1.weight
Shape: [128]
Values:
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1.]
============================================================
Layer: transformer.layers.1.norm1.bias
Shape: [128]
Values:
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0.]
============================================================
Layer: transformer.layers.1.norm2.weight
Shape: [128]
Values:
[1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.
 1. 1. 1. 1. 1. 1. 1. 1.]
============================================================
Layer: transformer.layers.1.norm2.bias
Shape: [128]
Values:
[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.
 0. 0. 0. 0. 0. 0. 0. 0.]
============================================================
Layer: classifier.weight
Shape: [10, 128]
Values:
[[-0.02015342 -0.04954664  0.01760883 ... -0.01101445 -0.02175976
  -0.01254563]
 [-0.01323652  0.051004   -0.02713848 ... -0.01868577 -0.01238459
   0.02296944]
 [-0.03033372 -0.00053059 -0.06251582 ... -0.06459272 -0.04107773
   0.05426391]
 ...
 [ 0.05323028 -0.03385917  0.03827263 ... -0.00488997 -0.03561667
  -0.07285517]
 [ 0.05845848  0.00499392 -0.05837085 ...  0.08032427 -0.0145705
  -0.0496702 ]
 [-0.06824107  0.05813535 -0.07752071 ...  0.0809012   0.04861832
  -0.06182228]]
============================================================
Layer: classifier.bias
Shape: [10]
Values:
[-0.07099517  0.08685329 -0.03784386  0.08102066  0.05518486  0.04404036
  0.01883565 -0.06736934  0.01456331  0.06280594]
============================================================
